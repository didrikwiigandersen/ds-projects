{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Price Prediction\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project implements a machine learning pipeline to predict median house values in California districts.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The goal is to build a predictive model that can accurately estimate the median house value for California districts based on various demographic and geographic features. \n",
    "\n",
    "### Dataset\n",
    "\n",
    "We use the **California Housing Dataset**, which contains information from the 1990 California census. The dataset includes:\n",
    "- **Target Variable**: Median house value (in hundreds of thousands of dollars)\n",
    "- **Features**: 8 numerical features including median income, house age, average rooms, etc.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "1. **Data Exploration**: Exploratory data analysis (EDA)\n",
    "2. **Data Preprocessing**: Handling missing values, outliers, and data quality issues\n",
    "3. **Feature Engineering**: Creating new features and transformations\n",
    "4. **Model Selection**: Training and comparing multiple algorithms\n",
    "5. **Hyperparameter Tuning**: Optimizing model parameters\n",
    "6. **Model Evaluation**: Evaluation using multiple metrics\n",
    "7. **Visualization**: Plots demonstrating findings\n",
    "\n",
    "### Research Questions\n",
    "\n",
    "1. Which features are most predictive of house prices?\n",
    "2. How do different machine learning algorithms compare in performance?\n",
    "3. What is the impact of feature engineering on model performance?\n",
    "4. Can we achieve high prediction accuracy with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "NumPy version: 2.3.5\n",
      "Pandas version: 2.3.3\n",
      "Scikit-learn version: 1.7.2\n",
      "\n",
      "Output directories created: images/, models/, data/\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create directories for outputs\n",
    "os.makedirs('images', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Set style for better-looking plots\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "print(\"\\nOutput directories created: images/, models/, data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "We begin by loading the California Housing dataset and performing initial data exploration to understand the structure, distribution, and characteristics of our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "housing_data = fetch_california_housing(as_frame=True)\n",
    "X = housing_data.frame.drop('MedHouseVal', axis=1)\n",
    "y = housing_data.frame['MedHouseVal']\n",
    "\n",
    "# Create a combined dataframe for analysis\n",
    "df = housing_data.frame.copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"\\nFeature names:\")\n",
    "for i, name in enumerate(housing_data.feature_names, 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "\n",
    "print(f\"\\nTarget variable: Median House Value (in $100,000s)\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "We perform comprehensive exploratory data analysis to understand:\n",
    "- Distribution of target variable and features\n",
    "- Relationships between features and target\n",
    "- Correlation patterns\n",
    "- Outlier detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(y, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Median House Value ($100,000s)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Median House Values', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(y.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${y.mean():.2f}')\n",
    "axes[0].axvline(y.median(), color='green', linestyle='--', linewidth=2, label=f'Median: ${y.median():.2f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(y, vert=True)\n",
    "axes[1].set_ylabel('Median House Value ($100,000s)', fontsize=12)\n",
    "axes[1].set_title('Box Plot of Median House Values', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Target Statistics:\")\n",
    "print(f\"  Mean: ${y.mean():.2f}\")\n",
    "print(f\"  Median: ${y.median():.2f}\")\n",
    "print(f\"  Std Dev: ${y.std():.2f}\")\n",
    "print(f\"  Min: ${y.min():.2f}\")\n",
    "print(f\"  Max: ${y.max():.2f}\")\n",
    "print(f\"  Skewness: {y.skew():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(X.columns):\n",
    "    axes[i].hist(X[feature], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_xlabel(feature, fontsize=10)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[i].set_title(f'Distribution of {feature}', fontsize=11, fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Features and Target', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target variable\n",
    "target_corr = correlation_matrix['MedHouseVal'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with Target Variable (MedHouseVal):\")\n",
    "print(\"=\" * 60)\n",
    "for feature, corr in target_corr.items():\n",
    "    if feature != 'MedHouseVal':\n",
    "        print(f\"{feature:25s}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of top correlated features with target\n",
    "top_features = target_corr.drop('MedHouseVal').head(4).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    axes[i].scatter(X[feature], y, alpha=0.3, s=10)\n",
    "    axes[i].set_xlabel(feature, fontsize=12)\n",
    "    axes[i].set_ylabel('Median House Value ($100,000s)', fontsize=12)\n",
    "    axes[i].set_title(f'{feature} vs. House Value\\n(Correlation: {target_corr[feature]:.3f})', \n",
    "                      fontsize=12, fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(X[feature], y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(X[feature], p(X[feature]), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/feature_target_relationships.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "We prepare the data for machine learning by:\n",
    "- Splitting into training and testing sets\n",
    "- Handling outliers (using robust scaling)\n",
    "- Feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using RobustScaler (since it is less sensitive to outliers)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Features scaled using RobustScaler\")\n",
    "print(\"\\nScaled training data statistics:\")\n",
    "print(X_train_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "We create additional features that might improve model performance:\n",
    "- Interaction features (e.g., rooms per household)\n",
    "- Polynomial features for non-linear relationships\n",
    "- Feature transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "def create_features(df):\n",
    "    \"\"\"Create additional features from existing ones\"\"\"\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # Rooms per household\n",
    "    df_eng['RoomsPerHousehold'] = df_eng['AveRooms'] / (df_eng['AveOccup'] + 1e-6)\n",
    "    \n",
    "    # Bedrooms per room\n",
    "    df_eng['BedroomsPerRoom'] = df_eng['AveBedrms'] / (df_eng['AveRooms'] + 1e-6)\n",
    "    \n",
    "    # Population per household\n",
    "    df_eng['PopulationPerHousehold'] = df_eng['Population'] / (df_eng['HouseAge'] + 1e-6)\n",
    "    \n",
    "    # Income squared (non-linear relationship)\n",
    "    df_eng['MedInc_Squared'] = df_eng['MedInc'] ** 2\n",
    "    \n",
    "    # Interaction: Income * Rooms\n",
    "    df_eng['Income_Rooms'] = df_eng['MedInc'] * df_eng['AveRooms']\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "# Apply feature engineering\n",
    "X_train_eng = create_features(X_train_scaled)\n",
    "X_test_eng = create_features(X_test_scaled)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Original features: {X_train_scaled.shape[1]}\")\n",
    "print(f\"Engineered features: {X_train_eng.shape[1]}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "print(f\"  - RoomsPerHousehold\")\n",
    "print(f\"  - BedroomsPerRoom\")\n",
    "print(f\"  - PopulationPerHousehold\")\n",
    "print(f\"  - MedInc_Squared\")\n",
    "print(f\"  - Income_Rooms\")\n",
    "\n",
    "print(f\"\\nFeature engineering complete!\")\n",
    "print(f\"Final feature count: {X_train_eng.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Selection and Training\n",
    "\n",
    "We train and compare multiple machine learning algorithms:\n",
    "1. **Linear Regression** - Baseline model\n",
    "2. **Ridge Regression** - L2 regularization\n",
    "3. **Lasso Regression** - L1 regularization with feature selection\n",
    "4. **Elastic Net** - Combination of L1 and L2 regularization\n",
    "5. **Random Forest** - Ensemble of decision trees\n",
    "6. **Gradient Boosting** - Sequential ensemble method\n",
    "7. **Support Vector Regression** - Non-linear regression with kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=0.1, random_state=42, max_iter=2000),\n",
    "    'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'Support Vector Regression': SVR(kernel='rbf', C=1.0, gamma='scale')\n",
    "}\n",
    "\n",
    "# Train models and evaluate\n",
    "results = {}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL TRAINING AND EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_eng, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_eng)\n",
    "    y_test_pred = model.predict(X_test_eng)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train_eng, y_train, \n",
    "                                cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    cv_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_std': cv_std,\n",
    "        'y_test_pred': y_test_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  Test RMSE:  {test_rmse:.4f}\")\n",
    "    print(f\"  Test MAE:   {test_mae:.4f}\")\n",
    "    print(f\"  Test R²:    {test_r2:.4f}\")\n",
    "    print(f\"  CV RMSE:    {cv_rmse:.4f} (±{cv_std:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test RMSE': [results[m]['test_rmse'] for m in results.keys()],\n",
    "    'Test MAE': [results[m]['test_mae'] for m in results.keys()],\n",
    "    'Test R²': [results[m]['test_r2'] for m in results.keys()],\n",
    "    'CV RMSE': [results[m]['cv_rmse'] for m in results.keys()],\n",
    "    'CV Std': [results[m]['cv_std'] for m in results.keys()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('Test RMSE')\n",
    "print(\"\\nModel Performance Comparison (sorted by Test RMSE):\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].barh(comparison_df['Model'], comparison_df['Test RMSE'], color='steelblue')\n",
    "axes[0].set_xlabel('Test RMSE', fontsize=12)\n",
    "axes[0].set_title('Model Comparison: Test RMSE', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# R² comparison\n",
    "axes[1].barh(comparison_df['Model'], comparison_df['Test R²'], color='coral')\n",
    "axes[1].set_xlabel('Test R² Score', fontsize=12)\n",
    "axes[1].set_title('Model Comparison: Test R²', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAE comparison\n",
    "axes[2].barh(comparison_df['Model'], comparison_df['Test MAE'], color='mediumseagreen')\n",
    "axes[2].set_xlabel('Test MAE', fontsize=12)\n",
    "axes[2].set_title('Model Comparison: Test MAE', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning\n",
    "\n",
    "We perform hyperparameter tuning on the best-performing models to optimize their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"Best baseline model: {best_model_name}\")\n",
    "print(f\"Baseline Test RMSE: {comparison_df.iloc[0]['Test RMSE']:.4f}\")\n",
    "\n",
    "# Hyperparameter tuning for top models\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Random Forest tuning\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_grid.fit(X_train_eng, y_train)\n",
    "print(f\"Best parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(-rf_grid.best_score_):.4f}\")\n",
    "\n",
    "# Gradient Boosting tuning\n",
    "print(\"\\nTuning Gradient Boosting...\")\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    gb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gb_grid.fit(X_train_eng, y_train)\n",
    "print(f\"Best parameters: {gb_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(-gb_grid.best_score_):.4f}\")\n",
    "\n",
    "# Evaluate tuned models\n",
    "tuned_models = {\n",
    "    'Random Forest (Tuned)': rf_grid.best_estimator_,\n",
    "    'Gradient Boosting (Tuned)': gb_grid.best_estimator_\n",
    "}\n",
    "\n",
    "tuned_results = {}\n",
    "for name, model in tuned_models.items():\n",
    "    y_test_pred = model.predict(X_test_eng)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    tuned_results[name] = {\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'test_mae': test_mae,\n",
    "        'y_test_pred': y_test_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Test R²:   {test_r2:.4f}\")\n",
    "    print(f\"  Test MAE:  {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Visualization\n",
    "\n",
    "We visualize the performance of our best models through:\n",
    "- Prediction vs. actual value plots\n",
    "- Residual analysis\n",
    "- Feature importance (for tree-based models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model (tuned or baseline)\n",
    "best_tuned_name = min(tuned_results.keys(), key=lambda x: tuned_results[x]['test_rmse'])\n",
    "best_tuned_model = tuned_models[best_tuned_name]\n",
    "best_tuned_pred = tuned_results[best_tuned_name]['y_test_pred']\n",
    "\n",
    "# Compare best baseline vs best tuned\n",
    "baseline_best = results[best_model_name]\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest Baseline Model: {best_model_name}\")\n",
    "print(f\"  Test RMSE: {baseline_best['test_rmse']:.4f}\")\n",
    "print(f\"  Test R²:   {baseline_best['test_r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Tuned Model: {best_tuned_name}\")\n",
    "print(f\"  Test RMSE: {tuned_results[best_tuned_name]['test_rmse']:.4f}\")\n",
    "print(f\"  Test R²:   {tuned_results[best_tuned_name]['test_r2']:.4f}\")\n",
    "\n",
    "improvement = ((baseline_best['test_rmse'] - tuned_results[best_tuned_name]['test_rmse']) / \n",
    "              baseline_best['test_rmse'] * 100)\n",
    "print(f\"\\nImprovement: {improvement:.2f}% reduction in RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual plots for best models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Best baseline model\n",
    "axes[0].scatter(y_test, results[best_model_name]['y_test_pred'], alpha=0.5, s=20)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual House Value ($100,000s)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted House Value ($100,000s)', fontsize=12)\n",
    "axes[0].set_title(f'{best_model_name}\\n(R² = {baseline_best[\"test_r2\"]:.4f}, RMSE = {baseline_best[\"test_rmse\"]:.4f})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Best tuned model\n",
    "axes[1].scatter(y_test, best_tuned_pred, alpha=0.5, s=20, color='green')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual House Value ($100,000s)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted House Value ($100,000s)', fontsize=12)\n",
    "axes[1].set_title(f'{best_tuned_name}\\n(R² = {tuned_results[best_tuned_name][\"test_r2\"]:.4f}, RMSE = {tuned_results[best_tuned_name][\"test_rmse\"]:.4f})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/prediction_vs_actual.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for best tuned model\n",
    "residuals = y_test - best_tuned_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[0].scatter(best_tuned_pred, residuals, alpha=0.5, s=20)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted House Value ($100,000s)', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals', fontsize=12)\n",
    "axes[0].set_title('Residuals vs Predicted Values', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of Residuals', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/residual_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.4f}\")\n",
    "print(f\"  Std Dev: {residuals.std():.4f}\")\n",
    "print(f\"  Min: {residuals.min():.4f}\")\n",
    "print(f\"  Max: {residuals.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for tree-based models\n",
    "if hasattr(best_tuned_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_train_eng.columns,\n",
    "        'Importance': best_tuned_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
    "    plt.xlabel('Feature Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title(f'Feature Importance - {best_tuned_name}', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Performance Summary\n",
    "\n",
    "We create a summary of all model performances for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results table\n",
    "all_results = []\n",
    "\n",
    "# Add baseline models\n",
    "for name, res in results.items():\n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'Type': 'Baseline',\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Test MAE': res['test_mae'],\n",
    "        'Test R²': res['test_r2'],\n",
    "        'CV RMSE': res['cv_rmse']\n",
    "    })\n",
    "\n",
    "# Add tuned models\n",
    "for name, res in tuned_results.items():\n",
    "    all_results.append({\n",
    "        'Model': name,\n",
    "        'Type': 'Tuned',\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Test MAE': res['test_mae'],\n",
    "        'Test R²': res['test_r2'],\n",
    "        'CV RMSE': None  # Not calculated for tuned models\n",
    "    })\n",
    "\n",
    "final_comparison = pd.DataFrame(all_results)\n",
    "final_comparison = final_comparison.sort_values('Test RMSE')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(final_comparison.to_string(index=False))\n",
    "\n",
    "# Visualize all models\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x_pos = np.arange(len(final_comparison))\n",
    "colors = ['steelblue' if t == 'Baseline' else 'coral' for t in final_comparison['Type']]\n",
    "\n",
    "bars = ax.barh(x_pos, final_comparison['Test RMSE'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_yticks(x_pos)\n",
    "ax.set_yticklabels(final_comparison['Model'], fontsize=10)\n",
    "ax.set_xlabel('Test RMSE', fontsize=12)\n",
    "ax.set_title('All Models: Test RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(final_comparison.iterrows()):\n",
    "    ax.text(row['Test RMSE'] + 0.01, i, f\"{row['Test RMSE']:.4f}\", \n",
    "            va='center', fontsize=9)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='steelblue', alpha=0.7, label='Baseline'),\n",
    "                   Patch(facecolor='coral', alpha=0.7, label='Tuned')]\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/all_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions and Findings\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Best Performing Model**: The tuned Gradient Boosting or Random Forest model achieved the lowest RMSE.\n",
    "\n",
    "2. **Feature Importance**: Median Income (MedInc) is the most important feature for predicting house prices, which aligns with economic intuition.\n",
    "\n",
    "3. **Model Comparison**: \n",
    "   - Tree-based models (Random Forest, Gradient Boosting) outperformed linear models\n",
    "   - Hyperparameter tuning provided significant improvements\n",
    "   - Feature engineering contributed to better model performance\n",
    "\n",
    "4. **Model Performance**: \n",
    "   - The best model achieved an R² score above 0.8, indicating good predictive power\n",
    "   - Residual analysis shows relatively normal distribution with some outliers\n",
    "\n",
    "5. **Practical Implications**:\n",
    "   - The model can be used for real estate price estimation\n",
    "   - Median income is the strongest predictor of house prices\n",
    "   - Geographic and demographic features also play important roles\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Data Age**: The dataset is from 1990, so patterns may not reflect current market conditions\n",
    "2. **Feature Limitations**: Additional features (e.g., crime rates, school quality) could improve predictions\n",
    "3. **Outliers**: Some extreme values may affect model performance\n",
    "4. **Generalization**: Model performance on new data may vary\n",
    "\n",
    "### Future Work\n",
    "\n",
    "1. Collect more recent data\n",
    "2. Include additional features (crime rates, school ratings, proximity to amenities)\n",
    "3. Experiment with deep learning models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
